{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import time\n",
    "\n",
    "from ImportData2D import get_label, getFilename, get_file_name\n",
    "from stlSlicer import getSlicer, slicecoor, rotatestl\n",
    "from imgSave import saveplot\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = getLabel(\"Occ_Sum\", \"median\", True, False,False)\n",
    "print(type(label[0]))\n",
    "label = getLabel(\"Occ_Sum\", \"median\", True, True,False)\n",
    "print(type(label[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_name = \"prep_test.tfrecords\"\n",
    "test_name = os.path.join(\"data\", test_name)\n",
    "print(test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "tffilename = \"train\"\n",
    "img_addr = list([1,2,3,4])\n",
    "print('Saving {} data: {}/{}'.format(tffilename,i, len(img_addr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "print(type(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_file_name(folder_name='../global_data/Original Format Data')\n",
    "print((a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['a','b','c']\n",
    "B = ['a','c', 'b']\n",
    "diff = set(A).symmetric_difference(set(B))\n",
    "diff2 = list(set(A) - set(B))\n",
    "print(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raise NameError(\"Hello\")\n",
    "    A = 1\n",
    "except NameError:\n",
    "    B = 2\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [0,1,2,3,4,5,6,7,8,9]\n",
    "index = 4\n",
    "A.pop(index*2)\n",
    "A.pop(index*2)\n",
    "print(A) # Expect 6,7 to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "A = './data/preparation_181_data_test_eval_address.txt'\n",
    "print(os.path.abspath(A))\n",
    "print(os.path.isfile(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grouped_address = ['/home/pasin/Documents/Google_Drive/Aa_TIT_LAB_Comp/Library/Tooth/Tooth/Model/my2DCNN/data/cross_section/PreparationScan_0_84140','/home/pasin/Documents/Google_Drive/Aa_TIT_LAB_Comp/Library/Tooth/Tooth/Model/my2DCNN/data/cross_section/PreparationScan_1_95138_0','/home/pasin/Documents/Google_Drive/Aa_TIT_LAB_Comp/Library/Tooth/Tooth/Model/my2DCNN/data/cross_section/PreparationScan_1_304138_45']\n",
    "grouped_address = [1,2,3]\n",
    "# define an empty list\n",
    "train_address = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open(A, 'r') as filehandle:  \n",
    "    for line in filehandle:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        current_name = line[:-1]\n",
    "        # print(current_name)\n",
    "        for i, name in enumerate(example_grouped_address):\n",
    "            \n",
    "            if current_name in name:\n",
    "                train_address.append(grouped_address[i])\n",
    "                grouped_address.remove(grouped_address[i])\n",
    "                example_grouped_address.remove(example_grouped_address[i])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "B = ast.literal_eval(error_file_names[0])\n",
    "print(B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_address = ['abc_0_0','abc_0_90','abc_0_45','abc_0_135','abc_1_0','abc_1_45','abc_1_90','abc_1_70']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_address.sort()\n",
    "print([s for s in train_address if 'abc_0' in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "b = ['Spears', \"Adele\", \"NDubz\", \"Nicole\", \"Cristina\"]\n",
    "a = [1,2,3,4,5]\n",
    "\n",
    "address = []\n",
    "for i,name in enumerate(b):\n",
    "    if 'a' in name:\n",
    "        address.append(a[i])\n",
    "        #a.remove(a[i])\n",
    "        #b.remove(b[i])\n",
    "        \n",
    "print(address)\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[0:(5-3)]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 4\n",
    "A = [i * b for i in [16, 16, 32, 16, 16, 16, 16, 16, 16, 512, 512]]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "A = {'learning_rate':0.00009123,'keep_prob':0.25, 'activation':tf.nn.relu, 'channels':[16,16,32]}\n",
    "# A = {'a':'b','c':'d'}\n",
    "w = csv.writer(open(\"output.csv\", \"w\"))\n",
    "for key, val in A.items():\n",
    "    w.writerow([key, val])\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
